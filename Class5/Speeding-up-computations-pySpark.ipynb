{"cells":[{"cell_type":"code","source":["import urllib.request"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["file_name = \"https://s3.amazonaws.com/h2o-airlines-unpacked/year2012.csv\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["### --- Read-in dataset by first moving file to cluster's local storage\n# Download file, per https://docs.databricks.com/_static/notebooks/zip-files-python.html:\nurllib.request.urlretrieve(file_name, '/tmp/df.csv')\n\n# Move file per to DBFS, per https://docs.databricks.com/_static/notebooks/zip-files-python.html:\ndbutils.fs.mv(\"file:/tmp/df.csv\", \"dbfs:/data/df.csv\")\n\n# Per https://spark.apache.org/docs/2.2.0/sql-programming-guide.html#datasets-and-dataframes, 'spark' is an existing SparkSession:\ndf_spark = spark.read.format('csv').options(header='true', inferSchema='true').load('dbfs:/data/df.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["display(df_spark)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\njava.lang.RuntimeException: abort: DriverClient destroyed\n\tat com.databricks.backend.daemon.driver.DriverClient.$anonfun$poll$3(DriverClient.scala:469)\n\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat com.databricks.threading.NamedExecutor$$anon$2.$anonfun$run$1(NamedExecutor.scala:326)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:230)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:265)\n\tat com.databricks.threading.NamedExecutor$$anon$2.run(NamedExecutor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":4},{"cell_type":"code","source":["# --- Make dataframe available to run SQL queries against:\ndf_spark.createOrReplaceTempView(\"df_spark\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\njava.lang.RuntimeException: abort: DriverClient destroyed\n\tat com.databricks.backend.daemon.driver.DriverClient.$anonfun$poll$3(DriverClient.scala:469)\n\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat com.databricks.threading.NamedExecutor$$anon$2.$anonfun$run$1(NamedExecutor.scala:326)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:230)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:265)\n\tat com.databricks.threading.NamedExecutor$$anon$2.run(NamedExecutor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":5},{"cell_type":"code","source":["df_carrier_counts = spark.sql(\"\"\"SELECT uniquecarrier, count(*) as N\n                                 FROM df_spark\n                                 GROUP BY uniquecarrier\n                                 ORDER BY uniquecarrier\"\"\")\ndf_carrier_counts.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\njava.lang.RuntimeException: abort: DriverClient destroyed\n\tat com.databricks.backend.daemon.driver.DriverClient.$anonfun$poll$3(DriverClient.scala:469)\n\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat com.databricks.threading.NamedExecutor$$anon$2.$anonfun$run$1(NamedExecutor.scala:326)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:230)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:265)\n\tat com.databricks.threading.NamedExecutor$$anon$2.run(NamedExecutor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"]}}],"execution_count":6}],"metadata":{"name":"Airlines","notebookId":2252219718088020},"nbformat":4,"nbformat_minor":0}
